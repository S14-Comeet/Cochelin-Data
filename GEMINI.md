# Comeet-Data

## Project Overview
The **Comeet-Data** project is a data collection and processing pipeline for the "Comeet" service. Its primary goal is to build a comprehensive dataset of **Specialty Cafes** in Seoul, specifically targeting the **Gangnam-gu**, **Seongdong-gu**, and **Mapo-gu** districts.

The project employs two main strategies:
1.  **Public Data Processing:** Filtering large datasets from the Small Enterprise and Market Service (SEMAS) to identify potential specialty cafes based on location and naming patterns.
2.  **Web Crawling:** Using Selenium to scrape Naver Map for detailed store information, including menus and bean details (origin, processing method), to verify "specialty" status.

## Key Directories & Files

### Root Directory
*   `schema.sql`: Defines the MySQL database schema for the Comeet service. Key tables include `stores`, `users`, `roasteries`, `beans`, `menus`, `reviews`, and `flavors`.
*   `preprocess_cafes.py`: A Python script that processes the SEMAS data (`소상공인시장진흥공단_상가(상권)정보...`). It filters cafes by district and excludes major franchises to isolate independent/specialty cafes.
*   `preprocess_cafe_dataset.py`: Similar to `preprocess_cafes.py` but processes `cafe_dataset.csv`. It includes logic to filter by city (Seoul) and district, and applies inclusion/exclusion rules based on keywords and franchise names.
*   `cafe_dataset.csv`: A raw dataset used as input for `preprocess_cafe_dataset.py`.
*   `stores_cafe_dataset_preprocessed.csv`: The output file generated by `preprocess_cafe_dataset.py`.

### `crawlers/` Directory
*   `crawl_specialty_cafes.py`: The main web crawler script. It uses **Selenium** to search Naver Map for specific keywords (e.g., "Gangnam Specialty Coffee") and extracts store details. It specifically looks for "bean information" in menus/descriptions to validate the cafe's specialty nature.
*   `data/`: Directory where crawled data is saved.
    *   `stores.csv`: Contains cafe details (name, address, coordinates, etc.).
    *   `menus.csv`: Contains menu items for the crawled cafes.
    *   `crawl_log.json`: Logs the crawling process, including search queries and errors.
*   `test_naver_place.py`, `debug_naver_map.py`: Helper scripts for testing and debugging the crawling logic.

## Data Processing Logic

### Preprocessing (`preprocess_cafes.py` / `preprocess_cafe_dataset.py`)
*   **Inclusion:**
    *   **Districts:** Gangnam-gu, Seongdong-gu, Mapo-gu.
    *   **Specialty Franchises:** Explicitly includes known specialty brands like "Blue Bottle", "Fritz", "Terarosa", etc.
*   **Exclusion:**
    *   **General Franchises:** Excludes mass-market chains (Ediya, Mega Coffee, Starbucks equivalents, etc.).
    *   **Keywords:** Excludes non-cafe businesses based on keywords (e.g., "Bakery", "Dessert", "Study", "Wine").

### Crawling (`crawlers/crawl_specialty_cafes.py`)
*   **Target:** Naver Map.
*   **Verification:** A store is saved only if it matches the district criteria and contains "bean information" (e.g., "Ethiopia", "Washed", "Single Origin") in its description or menu.
*   **Output:** Generates `stores.csv` and `menus.csv` formatted to match the `schema.sql` structure.

## Setup & Usage

### Prerequisites
*   Python 3.x
*   Google Chrome (for Selenium)

### Installation
Install the required Python packages (inferred):
```bash
pip install selenium webdriver_manager pandas
```

### Running the Crawler
To start the Naver Map crawler:
```bash
python crawlers/crawl_specialty_cafes.py
```
*   **Note:** The crawler runs in headless mode by default. Check `setup_driver()` in the script to modify options.

### Running Preprocessing
To process the local CSV datasets:
```bash
python preprocess_cafes.py
# or
python preprocess_cafe_dataset.py
```

## Database Schema Highlights
The `schema.sql` file defines a rich data model:
*   **stores**: Core cafe information.
*   **beans**: Details about coffee beans (origin, farm, variety, processing).
*   **menus**: Menu items linked to stores.
*   **menu_bean_mappings**: Many-to-many relationship linking menus to specific beans.
*   **cupping_notes**: Detailed sensory scores (fragrance, aroma, acidity, etc.) for coffee reviews.
*   **flavors**: Hierarchical flavor notes based on the SCA Flavor Wheel.
